# Artistic Style Transfer with TensorFlow Lite

```elixir
Mix.install([
  {:tflite_elixir, "~> 0.1.4"},
  {:evision, "~> 0.1.8"},
  {:kino, "~> 0.8.0"},
  {:req, "~> 0.3.0"}
])
```

## Introduction

One of the most exciting developments in deep learning to come out recently is
[artistic style transfer](https://arxiv.org/abs/1508.06576), or the ability to
create a new image, known as a
[pastiche](https://en.wikipedia.org/wiki/Pastiche), based on two input images:
one representing the artistic style and one representing the content.

Using this technique, we can generate beautiful new artworks in a range of
styles.

https://www.tensorflow.org/lite/examples/style_transfer/overview

## Understand the model architecture

![](https://storage.googleapis.com/download.tensorflow.org/models/tflite/arbitrary_style_transfer/architecture.png)

This Artistic Style Transfer model consists of two submodels:

1. **Style Prediciton Model**: A MobilenetV2-based neural network that takes an
   input style image to a 100-dimension style bottleneck vector.
2. **Style Transform Model**: A neural network that takes apply a style
   bottleneck vector to a content image and creates a stylized image.

## Download data files

Download the content and style images, and the pre-trained TensorFlow Lite models.

```elixir
downloads_dir = System.tmp_dir!()
# for nerves demo user
# change to a directory with write-permission
# downloads_dir = "/data/livebook"

download = fn url ->
  save_as = Path.join(downloads_dir, URI.encode_www_form(url))

  unless File.exists?(save_as) do
    %{status: 200} = Req.get!(url, output: save_as)
  end

  save_as
end

data_files =
  [
    {
      :content,
      "https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg"
    },
    {
      :style,
      "https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg"
    },
    {
      :style_predict,
      "https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite"
    },
    {
      :style_transform,
      "https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite"
    }
  ]
  |> Enum.map(fn {key, url} ->
    Task.async(fn -> {key, download.(url)} end)
  end)
  |> Task.await_many(:timer.seconds(30))
  |> Map.new()
```

## Alias modules

```elixir
alias Evision, as: Cv
alias TFLiteElixir, as: TFLite
```

## Pre-process the inputs

* The content image and the style image must be RGB images with pixel values
  being float32 numbers between [0..1].
* The style image size must be (1, 256, 256, 3). We central crop the image and
  resize it.
* The content image must be (1, 384, 384, 3). We central crop the image and
  resize it.

```elixir
# Function to load an image from a file, and add a batch dimension.
load_img = fn path_to_img ->
  %Nx.Tensor{} =
    path_to_img
    |> Cv.imread()
    |> Cv.cvtColor(Cv.Constant.cv_COLOR_BGR2RGB(), dstCn: 3)
    |> Cv.Mat.to_nx()
    |> Nx.new_axis(0)
    |> Nx.as_type({:f, 32})
end

# Function to pre-process by resizing an central cropping it.
preprocess_image = fn image, target_dim ->
  nil
  # TODO: convert python to elixir
  #
  # # Resize the image so that the shorter dimension becomes 256px.
  # shape = tf.cast(tf.shape(image)[1:-1], tf.float32)
  # short_dim = min(shape)
  # scale = target_dim / short_dim
  # new_shape = tf.cast(shape * scale, tf.int32)
  # image = tf.image.resize(image, new_shape)

  # # Central crop the image.
  # image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)
end

# Load the input images.
content_image = %Nx.Tensor{} = load_img.(data_files.content)
style_image = %Nx.Tensor{} = load_img.(data_files.style)

# # Preprocess the input images.
# preprocessed_content_image = preprocess_image.(content_image, 384)
# preprocessed_style_image = preprocess_image.(style_image, 256)

# IO.puts("Style Image Shape:", preprocessed_style_image.shape)
# IO.puts("Content Image Shape:", preprocessed_content_image.shape)
```

## Visualize the inputs

```elixir
# def imshow(image, title=None):
#   if len(image.shape) > 3:
#     image = tf.squeeze(image, axis=0)

#   plt.imshow(image)
#   if title:
#     plt.title(title)

# plt.subplot(1, 2, 1)
# imshow(preprocessed_content_image, 'Content Image')

# plt.subplot(1, 2, 2)
# imshow(preprocessed_style_image, 'Style Image')
```

## Run style transfer with TensorFlow Lite

### Style prediction

```elixir
# # Function to run style prediction on preprocessed style image.
# def run_style_predict(preprocessed_style_image):
#   # Load the model.
#   interpreter = tf.lite.Interpreter(model_path=style_predict_path)

#   # Set model input.
#   interpreter.allocate_tensors()
#   input_details = interpreter.get_input_details()
#   interpreter.set_tensor(input_details[0]["index"], preprocessed_style_image)

#   # Calculate style bottleneck.
#   interpreter.invoke()
#   style_bottleneck = interpreter.tensor(
#       interpreter.get_output_details()[0]["index"]
#       )()

#   return style_bottleneck

# # Calculate style bottleneck for the preprocessed style image.
# style_bottleneck = run_style_predict(preprocessed_style_image)
# print('Style Bottleneck Shape:', style_bottleneck.shape)
```

### Style transform

```elixir
# # Run style transform on preprocessed style image
# def run_style_transform(style_bottleneck, preprocessed_content_image):
#   # Load the model.
#   interpreter = tf.lite.Interpreter(model_path=style_transform_path)

#   # Set model input.
#   input_details = interpreter.get_input_details()
#   interpreter.allocate_tensors()

#   # Set model inputs.
#   interpreter.set_tensor(input_details[0]["index"], preprocessed_content_image)
#   interpreter.set_tensor(input_details[1]["index"], style_bottleneck)
#   interpreter.invoke()

#   # Transform content image.
#   stylized_image = interpreter.tensor(
#       interpreter.get_output_details()[0]["index"]
#       )()

#   return stylized_image

# # Stylize the content image using the style bottleneck.
# stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)

# # Visualize the output.
# imshow(stylized_image, 'Stylized Image')
```

### Style blending

```elixir
# # Calculate style bottleneck of the content image.
# style_bottleneck_content = run_style_predict(
#   preprocess_image(content_image, 256)
# )
```

```elixir
# # Define content blending ratio between [0..1].
# # 0.0: 0% style extracts from content image.
# # 1.0: 100% style extracted from content image.
# content_blending_ratio = 0.5

# # Blend the style bottleneck of style image and content image
# style_bottleneck_blended = content_blending_ratio * style_bottleneck_content \
#                            + (1 - content_blending_ratio) * style_bottleneck

# # Stylize the content image using the style bottleneck.
# stylized_image_blended = run_style_transform(style_bottleneck_blended,
#                                              preprocessed_content_image)

# # Visualize the output.
# imshow(stylized_image_blended, 'Blended Stylized Image')
```
