# Inference on TPU

## Section

```elixir
# for nerves demo user
# change to a directory with write-permission
File.cd!("/data/livebook")
```

<!-- livebook:{"output":true} -->

```
:ok
```

```elixir
defmodule Helper do
  def download!(url, save_as, overwrite \\ false)

  def download!(url, save_as, false) do
    unless File.exists?(save_as) do
      download!(url, save_as, true)
    end

    :ok
  end

  def download!(url, save_as, true) do
    http_opts = []
    opts = [body_format: :binary]
    arg = {url, []}

    body =
      case :httpc.request(:get, arg, http_opts, opts) do
        {:ok, {{_, 200, _}, _, body}} ->
          body

        {:error, reason} ->
          raise inspect(reason)
      end

    File.write!(save_as, body)
  end
end
```

<!-- livebook:{"output":true} -->

```
{:module, Helper, <<70, 79, 82, 49, 0, 0, 10, ...>>, {:download!, 3}}
```

```elixir
# class labels
Helper.download!(
  "https://raw.githubusercontent.com/cocoa-xu/tflite_elixir/main/test/test_data/inat_bird_labels.txt",
  "inat_bird_labels.txt"
)

# CPU model
Helper.download!(
  "https://raw.githubusercontent.com/cocoa-xu/tflite_elixir/main/test/test_data/mobilenet_v2_1.0_224_inat_bird_quant.tflite",
  "mobilenet_v2_1.0_224_inat_bird_quant.tflite"
)

# TPU model
Helper.download!(
  "https://raw.githubusercontent.com/cocoa-xu/tflite_elixir/main/test/test_data/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite",
  "mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite"
)

# test image
Helper.download!(
  "https://raw.githubusercontent.com/cocoa-xu/tflite_elixir/main/test/test_data/parrot.jpeg",
  "parrot.jpeg"
)
```

<!-- livebook:{"output":true} -->

```
:ok
```

```elixir
defmodule ClassifyImage do
  @moduledoc """
  Image classification mix task: `mix help classify_image`

  Command line arguments:

  - `-m`, `--model`: *Required*. File path of .tflite file.
  - `-i`, `--input`: *Required*. Image to be classified.
  - `-l`, `--labels`: File path of labels file.
  - `-k`, `--top`: Default to `1`. Max number of classification results.
  - `-t`, `--threshold`: Default to `0.0`. Classification score threshold.
  - `-c`, `--count`: Default to `1`. Number of times to run inference.
  - `-a`, `--mean`: Default to `128.0`. Mean value for input normalization.
  - `-s`, `--std`: Default to `128.0`. STD value for input normalization.
  - `--use-tpu`: Default to false. Add this option to use Coral device.
  - `--tpu`: Default to `""`. Coral device name.
    - `""`      -- any TPU device
    - `"usb"`   -- any TPU device on USB bus
    - `"pci"`   -- any TPU device on PCIe bus
    - `":N"`    -- N-th TPU device, e.g. `":0"`
    - `"usb:N"` -- N-th TPU device on USB bus, e.g. `"usb:0"`
    - `"pci:N"` -- N-th TPU device on PCIe bus, e.g. `"pci:0"`

  Code based on [classify_image.py](https://github.com/google-coral/pycoral/blob/master/examples/classify_image.py)
  """

  alias TFLiteElixir.Interpreter, as: Interpreter
  alias TFLiteElixir.InterpreterBuilder, as: InterpreterBuilder
  alias TFLiteElixir.TfLiteTensor, as: TFTensor
  alias TFLiteElixir.FlatBufferModel, as: FlatBufferModel

  @shortdoc "Image Classification"
  def run(args) do
    default_values = [
      top: 1,
      threshold: 0.0,
      count: 1,
      mean: 128.0,
      std: 128.0,
      use_tpu: false,
      tpu: ""
    ]

    args =
      Keyword.merge(args, default_values, fn _k, user, default ->
        if user == nil do
          default
        else
          user
        end
      end)

    model = load_model(args[:model])
    input_image = load_input(args[:input])
    labels = load_labels(args[:labels])

    tpu_context =
      if args[:use_tpu] do
        TFLiteElixir.Coral.getEdgeTpuContext!(args[:tpu])
      else
        nil
      end

    interpreter = make_interpreter(model, args[:use_tpu], tpu_context)
    Interpreter.allocateTensors!(interpreter)

    [input_tensor_number | _] = Interpreter.inputs!(interpreter)
    [output_tensor_number | _] = Interpreter.outputs!(interpreter)
    input_tensor = Interpreter.tensor!(interpreter, input_tensor_number)

    if input_tensor.type != {:u, 8} do
      raise ArgumentError, "Only support uint8 input type."
    end

    {h, w} =
      case input_tensor.shape do
        [_n, h, w, _c] ->
          {h, w}

        [_n, h, w] ->
          {h, w}

        shape ->
          raise RuntimeError, "not sure the input shape, got #{inspect(shape)}"
      end

    input_image = StbImage.resize(input_image, h, w)

    [scale] = input_tensor.quantization_params.scale
    [zero_point] = input_tensor.quantization_params.zero_point
    mean = args[:mean]
    std = args[:std]

    if abs(scale * std - 1) < 0.00001 and abs(mean - zero_point) < 0.00001 do
      # Input data does not require preprocessing.
      %StbImage{data: input_data} = input_image
      input_data
    else
      # Input data requires preprocessing
      StbImage.to_nx(input_image)
      |> Nx.subtract(mean)
      |> Nx.divide(std * scale)
      |> Nx.add(zero_point)
      |> Nx.clip(0, 255)
      |> Nx.as_type(:u8)
      |> Nx.to_binary()
    end
    |> then(&TFTensor.set_data!(input_tensor, &1))

    IO.puts("----INFERENCE TIME----")

    for _ <- 1..args[:count] do
      start_time = :os.system_time(:microsecond)
      Interpreter.invoke!(interpreter)
      end_time = :os.system_time(:microsecond)
      inference_time = (end_time - start_time) / 1000.0
      IO.puts("#{Float.round(inference_time, 1)}ms")
    end

    output_data = Interpreter.output_tensor!(interpreter, 0)
    output_tensor = Interpreter.tensor!(interpreter, output_tensor_number)
    scores = get_scores(output_data, output_tensor)
    sorted_indices = Nx.argsort(scores, direction: :desc)
    top_k = Nx.take(sorted_indices, Nx.iota({args[:top]}))
    scores = Nx.to_flat_list(Nx.take(scores, top_k))
    top_k = Nx.to_flat_list(top_k)

    IO.puts("-------RESULTS--------")

    if labels != nil do
      Enum.zip(top_k, scores)
      |> Enum.each(fn {class_id, score} ->
        IO.puts("#{Enum.at(labels, class_id)}: #{Float.round(score, 5)}")
      end)
    else
      Enum.zip(top_k, scores)
      |> Enum.each(fn {class_id, score} ->
        IO.puts("#{class_id}: #{Float.round(score, 5)}")
      end)
    end

    interpreter
  end

  defp load_model(nil) do
    raise ArgumentError, "empty value for argument '--model'"
  end

  defp load_model(model_path) do
    FlatBufferModel.buildFromBuffer!(File.read!(model_path))
  end

  defp load_input(nil) do
    raise ArgumentError, "empty value for argument '--input'"
  end

  defp load_input(input_path) do
    with {:ok, input_image} <- StbImage.read_file(input_path) do
      input_image
    else
      {:error, error} ->
        raise RuntimeError, error
    end
  end

  defp load_labels(nil), do: nil

  defp load_labels(label_file_path) do
    File.read!(label_file_path)
    |> String.split("\n")
  end

  defp make_interpreter(model, false, _tpu_context) do
    resolver = TFLiteElixir.Ops.Builtin.BuiltinResolver.new!()
    builder = InterpreterBuilder.new!(model, resolver)
    interpreter = Interpreter.new!()
    InterpreterBuilder.setNumThreads!(builder, 2)
    :ok = InterpreterBuilder.build!(builder, interpreter)
    Interpreter.setNumThreads!(interpreter, 2)
    interpreter
  end

  defp make_interpreter(model, true, tpu_context) do
    TFLiteElixir.Coral.makeEdgeTpuInterpreter!(model, tpu_context)
  end

  defp get_scores(output_data, %TFTensor{type: dtype = {:u, _}} = output_tensor) do
    scale = Nx.tensor(output_tensor.quantization_params.scale)
    zero_point = Nx.tensor(output_tensor.quantization_params.zero_point)

    Nx.from_binary(output_data, dtype)
    |> Nx.as_type({:s, 64})
    |> Nx.subtract(zero_point)
    |> Nx.multiply(scale)
  end

  defp get_scores(output_data, %TFTensor{type: dtype = {:s, _}} = output_tensor) do
    [scale] = output_tensor.quantization_params.scale
    [zero_point] = output_tensor.quantization_params.zero_point

    Nx.from_binary(output_data, dtype)
    |> Nx.as_type({:s, 64})
    |> Nx.subtract(zero_point)
    |> Nx.multiply(scale)
  end

  defp get_scores(output_data, %TFTensor{type: dtype}) do
    Nx.from_binary(output_data, dtype)
  end
end
```

<!-- livebook:{"output":true} -->

```
warning: module attribute @shortdoc was set but never used
  #cell:32

```

<!-- livebook:{"output":true} -->

```
{:module, ClassifyImage, <<70, 79, 82, 49, 0, 0, 43, ...>>, {:get_scores, 2}}
```

```elixir
interpreter =
  ClassifyImage.run(
    model: "mobilenet_v2_1.0_224_inat_bird_quant.tflite",
    input: "parrot.jpeg",
    labels: "inat_bird_labels.txt",
    top: 3,
    threshold: 0.3,
    count: 5,
    mean: 128.0,
    std: 128.0,
    use_tpu: false,
    tpu: ""
  )

interpreter = nil
```

<!-- livebook:{"output":true} -->

```
----INFERENCE TIME----
47.4ms
46.9ms
45.9ms
45.8ms
45.7ms
-------RESULTS--------
Ara macao (Scarlet Macaw): 0.70703
Platycercus elegans (Crimson Rosella): 0.07813
Coracias caudatus (Lilac-breasted Roller): 0.01953
```

<!-- livebook:{"output":true} -->

```
nil
```

```elixir
interpreter =
  ClassifyImage.run(
    model: "mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite",
    input: "parrot.jpeg",
    labels: "inat_bird_labels.txt",
    top: 3,
    threshold: 0.3,
    count: 5,
    mean: 128.0,
    std: 128.0,
    use_tpu: true,
    tpu: "usb"
  )

interpreter = nil
```

<!-- livebook:{"output":true} -->

```
----INFERENCE TIME----
17.3ms
4.4ms
4.3ms
4.3ms
4.3ms
-------RESULTS--------
Ara macao (Scarlet Macaw): 0.71875
Platycercus elegans (Crimson Rosella): 0.07031
Coracias caudatus (Lilac-breasted Roller): 0.01953
```

<!-- livebook:{"output":true} -->

```
nil
```
